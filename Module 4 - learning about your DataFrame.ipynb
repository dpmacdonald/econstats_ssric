{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd1e7476",
   "metadata": {},
   "source": [
    "# 1. Introduction: Learning about your DataFrame\n",
    "\n",
    "Welcome to the SSRIC Instructional Modules for the project, \"Teaching Statistics and Economic Data Analysis in Python with Jupyter Notebooks\", by Daniel MacDonald, Associate Professor and Chair, Economics Department, CSU San Bernardino. These were written in Summer 2023.\n",
    "\n",
    "Most of the modules draw extensively on Kevin Sheppard's e-book, *Introduction to Python for Econometrics, Statistics, and Data Analysis*, available here: https://bashtage.github.io/kevinsheppard.com/files/teaching/python/notes/python_introduction_2021.pdf. \n",
    "\n",
    "Rather than begin instruction in Python through the core tools of computer programming (such as conditions, loops, and functions), Sheppard begins with Python's major \"containers\", or data structures. Through practice, I have learned that this is an effective method for teaching Python to economics majors.\n",
    "\n",
    "The learning objectives of this set of Instructional Modules are as follows. By the end of these modules, students will be able to...\n",
    "\n",
    "1. Create data structures in Python based on economic data\n",
    "1. Summarize the statistical properties of economic data (median, mean, max, min, correlation) using Python\n",
    "1. Create and manage economic data: create new columns and rows, merge and append, and import data from .csv and .xlsx files into Python\n",
    "1. Visualize economic data using line and scatterplots\n",
    "\n",
    "The objectives/content of Module 4 are as follows. By the end of this module, students will be able to...\n",
    "\n",
    "1. Add indexes to a Pandas DataFrame\n",
    "1. Slice economic DataFrames with `.loc[]` and other conditional operations\n",
    "1. Import Excel files into Python for economic and statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4502a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34024f58",
   "metadata": {},
   "source": [
    "## 1.1 More on indexing\n",
    "\n",
    "You can create indexes for your dataframes just as you did for Series. See below for an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd019e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_dict={'state': ['California', 'California', 'Oregon', 'Oregon', 'Arizona'], \n",
    "                         'year': [2021, 2022, 2021, 2022, 2022],\n",
    "                         'urate': [5.8, 4.1, 4.2, 4.5, 4.0]}\n",
    "index=['one', 'two', 'three', 'four', 'five']\n",
    "unemployment=pd.DataFrame(unemployment_dict, index=index)\n",
    "print(unemployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ced9e9d",
   "metadata": {},
   "source": [
    "Suppose you forget to specify the index when you initially create the dataframe. You can always go back and create an index out of a list, and then edit over the existing index using the syntax below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920df989",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_index=['five', 'six', 'seven', 'eight', 'nine']\n",
    "unemployment.index=new_index\n",
    "print(unemployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192ab1a6",
   "metadata": {},
   "source": [
    "...And if you want to set a current column to be an index, use `set_index` and `inplace=True` to \"save\" your changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee041433",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.set_index('state', inplace=True)\n",
    "print(unemployment)\n",
    "print(unemployment.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d307803",
   "metadata": {},
   "source": [
    "## 1.2 Try it yourself (part 1 of 2): set index\n",
    "\n",
    "Using the information below, create a DataFrame and set its index as the County name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f1ef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict={'unemployment': [4.5, 4.2, 4.1, 3.0, 3.3, 16.7], 'employment': [95.5, 95.8, 95.9, 97.0, 96.7, 83.3], \n",
    "           'status': ['coastal', 'inland', 'inland', 'coastal', 'coastal', 'inland']}\n",
    "counties=['Los Angeles', 'Riverside', 'San Bernardino', 'Orange', 'San Diego', 'Imperial']\n",
    "\n",
    "#Try it yourself: create a DataFrame from the dictionary above (call it \"df\") and set its index=counties:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3a7580",
   "metadata": {},
   "source": [
    "## 1.3 Try it yourself (part 2 of 2): change index\n",
    "\n",
    "Suppose you wanted to enter the county FIPS codes as an index, instead of their names. Set the new index based on the data below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013cde51",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_fips=['06037', '06065', '06071', '06059', '06073', '06025']\n",
    "\n",
    "#Try it yourself: change the index of the DataFrame you created above, using county_fips:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddc8236",
   "metadata": {},
   "source": [
    "# 2. Learning more about your DataFrame\n",
    "\n",
    "It's not just about statistics (i.e., `describe()`) - you can learn a lot about your DataFrame with other tools. \n",
    "\n",
    "There are a lot of DataFrame attributes - while we can't go over all of them, it's important just to know that if there is something you want to get out of your data, most likely Pandas can help you out with that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddd71aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_dict={'state': ['California', 'California', 'Oregon', 'Oregon', 'Arizona'], \n",
    "                         'year': [2021, 2022, 2021, 2022, 2022],\n",
    "                         'urate': [5.8, 4.1, 4.2, 4.5, 4.0]}\n",
    "index=['one', 'two', 'three', 'four', 'five']\n",
    "unemployment=pd.DataFrame(unemployment_dict, index=index)\n",
    "\n",
    "print('Prints a list of the columns:\\n\\n', unemployment.columns)\n",
    "print('\\nPrints the values and how often they appear:\\n\\n', unemployment['year'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ead9f2b",
   "metadata": {},
   "source": [
    "## 2.1 Slicing\n",
    "\n",
    "Another way to learn more about DataFrames is through the clever use of Booleans. For this, we will need to work with a larger dataset. See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d3875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wage_lq=np.array([[1342., 0.91], [732.,0.14],[793.,0.76],[977.,0.97],[840.,0.96],\n",
    "                  [1084.,0.85],[1280.,0.93],[694.,0.75],[955.,0.76],[995.,0.95]])\n",
    "counties = ['Alameda', 'Alpine', 'Amador', 'Butte', 'Calaveras', 'Colusa', 'Contra Costa', 'Del Norte', 'El Dorado', 'Fresno']\n",
    "\n",
    "df=pd.DataFrame(wage_lq, columns=['weekly_wage', 'loc_q'], index=counties)\n",
    "print(df)\n",
    "\n",
    "\n",
    "# Slice the dataset by weekly_wage>=1000, or create a new dataset based on that condition:\n",
    "\n",
    "print(df[df['weekly_wage']>=1000])\n",
    "df_1000=df[df['weekly_wage']>=1000]\n",
    "print(df_1000)\n",
    "\n",
    "#Slice the dataset by loc_q<0.9:\n",
    "\n",
    "print(df[df['loc_q']<0.9])\n",
    "\n",
    "#Multiple conditions:\n",
    "\n",
    "df_new=df[(df['weekly_wage']>=1000) | (df['loc_q']<0.9)]\n",
    "print(df_new)\n",
    "\n",
    "df_new=df[(df['weekly_wage']>=1000) & (df['loc_q']<0.9)]\n",
    "print(df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854bb56e",
   "metadata": {},
   "source": [
    "## 2.2 Try it yourself: using conditions to break down datasets\n",
    "\n",
    "Using the DataFrame below, narrow your DataFrame down according to the following conditions:\n",
    "\n",
    "1. Unemployment rate greater than 4%\n",
    "1. Unemployment rate less than 4%\n",
    "1. (Challenge!) only inland counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae54c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict={'unemployment': [4.5, 4.2, 4.1, 3.0, 3.3, 16.7], 'employment': [95.5, 95.8, 95.9, 97.0, 96.7, 83.3], \n",
    "           'status': ['coastal', 'inland', 'inland', 'coastal', 'coastal', 'inland']}\n",
    "counties=['Los Angeles', 'Riverside', 'San Bernardino', 'Orange', 'San Diego', 'Imperial']\n",
    "\n",
    "df=pd.DataFrame(data_dict, index=counties)\n",
    "print(df)\n",
    "\n",
    "#Try it: write your code for 1-3 below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357367b0",
   "metadata": {},
   "source": [
    "# 3. Importing Excel files into Python\n",
    "\n",
    "Some of the most important work with DataFrames starts before they are even in Python.\n",
    "\n",
    "Use `pd.read_csv` and `pd.read_excel` to \"import\" CSV or Excel files into Python. \n",
    "\n",
    "Importing Excel files will not only allow us to see more \"real world\" examples of economic data, but it will also allow us to learn about more advanced operations on our data.\n",
    "\n",
    "You will need the \"module 4 data.xlsx\" in the same folder as this Jupyter Notebook, for the code below to work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bb38f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('module 4 data.xlsx')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52a29d7",
   "metadata": {},
   "source": [
    "## 3.1 Comment on the above\n",
    "\n",
    "This is our first \"bigger\" DataFrame - all 58 counties in California. Take a minute and look through the object and think about what looks right, what doesn't - and what you might want to change. A few things could come to mind:\n",
    "\n",
    "1. What is going on with area code?\n",
    "1. It would be nice if all area information were also in a single column\n",
    "1. It would be nice if all the date information were in a single column\n",
    "1. Does 'urate' equal the unemployment rate? \n",
    "\n",
    "Economic data analysis is partly about **getting your data into a format that's readable and easy to work with** - and so that's what we'll spend the remainder of today doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb193861",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('columns:', df.columns)\n",
    "print('\\nnumber of observations (i.e., counties)=', len(df))\n",
    "print('\\n', df[['urate', 'unemployment', 'employment']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfd0e7f",
   "metadata": {},
   "source": [
    "## 3.2 Fixing area code\n",
    "\n",
    "Area code is very long. Is there any way to format it down to something more readable? \n",
    "\n",
    "First of all, we should be able to see that 'area_code' is really the county FIPS. Once we know that information, we can dig a little deeper to see how to solve the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10795f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['area_code'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3d4737",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['countyfips']=(df['area_code']/100000000).astype(int) #We use our observation that 'area_code' is int type with 8 zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d545a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fips']=df['state_code']*1000+df['countyfips']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1db6433",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[['state_code', 'countyfips', 'fips']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b349add",
   "metadata": {},
   "source": [
    "## 3.3 Check if 'urate' is the unemployment rate\n",
    "\n",
    "We can check this by calculating the unemployment rate ourselves and comparing it to 'urate'. We know that:\n",
    "\n",
    "$\\text{unemployment rate} = 100*\\frac{\\text{unemployment}}{\\text{labor force}}$\n",
    "\n",
    "we know further that \n",
    "\n",
    "$\\text{labor force} = \\text{unemployment} + \\text{employment}$\n",
    "\n",
    "Thus:\n",
    "\n",
    "$\\text{unemployment rate} = 100*\\frac{\\text{unemployment}}{\\text{unemployment} + \\text{employment}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7077b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['unemployment_rate']=np.round(100*(df['unemployment']/(df['unemployment']+df['employment'])), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4e6e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[['urate', 'unemployment_rate']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad98e90d",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "There is still more to explore with this basic dataset, but these notes show the potential tools you have to importing, cleaning, and overall adjustment of your dataset to your own needs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
